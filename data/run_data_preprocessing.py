"""
==========================================================
í™˜ê²½ ë° ì„¤ì¹˜ ì•ˆë‚´ (Python 3.10 ê¸°ì¤€)
==========================================================

1ï¸âƒ£ Python ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
> conda create -n capstone python=3.10
> conda activate capstone

2ï¸âƒ£ í•„ìš”í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
> pip install faster-whisper pydub numpy tqdm kospellpy
> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

3ï¸âƒ£ ffmpeg ì„¤ì¹˜ (Windows)
> choco install ffmpeg
> ffmpeg -version

==========================================================
ğŸ’¡ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¡°ì ˆ ì•ˆë‚´ (faster-whisper)
==========================================================

1. ëª¨ë¸ ì‚¬ì´ì¦ˆ (MODEL_SIZE)
- "tiny", "base", "small", "medium", "large-v2", "large-v3" ë“± ì„ íƒ ê°€ëŠ¥
- í¬ê¸°ê°€ í´ìˆ˜ë¡ ì •í™•ë„ â†‘, ì†ë„ â†“, VRAM â†‘
- ì˜ˆ: MODEL_SIZE="large-v3"

2. Beam search í¬ê¸° (BEAM_SIZE)
- ë””ì½”ë”© ì‹œ íƒìƒ‰ ê¹Šì´ë¥¼ ì¡°ì ˆ
- ê°’ì´ í´ìˆ˜ë¡ ì •í™•ë„ â†‘, ì†ë„ â†“
- ì˜ˆ: BEAM_SIZE=5

3. ì˜¤ë²„ë© ì‹œê°„ (OVERLAP_SEC)
- VAD ê¸°ë°˜ ë¶„í•  ì‹œ ì¸ì ‘ êµ¬ê°„ ì¤‘ì²© ì‹œê°„
- ìŒì„± êµ¬ê°„ ì˜ë¦¼ ë°©ì§€ìš©
- ì˜ˆ: OVERLAP_SEC=2 (ì´ˆ)

4. ë§ì¶¤ë²• ê²€ì‚¬ ë°°ì¹˜ í¬ê¸° (BATCH_SENTENCE_COUNT)
- í•œ ë²ˆì— ë§ì¶¤ë²• ê²€ì‚¬í•  ë¬¸ì¥ ìˆ˜
- ê°’ì´ í´ìˆ˜ë¡ ì²˜ë¦¬ íš¨ìœ¨ â†‘, ë©”ëª¨ë¦¬ ì‚¬ìš© â†‘
- ì˜ˆ: BATCH_SENTENCE_COUNT=20

==========================================================
ğŸ’¡ ì‹¤í–‰ ì˜ˆì‹œ
==========================================================

from refine_transcription import refine_transcription
from faster_whisper import WhisperModel
import torch
import os

# --- ëª¨ë¸ í•œ ë²ˆë§Œ ë¡œë“œ ---
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"
model = WhisperModel("large-v3", device=device, compute_type=compute_type)

# --- ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ---
INPUT_MP3_FILE = "./ìˆ˜ì‚¬ê¸°ê´€ ì‚¬ì¹­í˜•(ê²€ì°°, ê²½ì°° ë“±)/63.mp3"
OUTPUT_FILE = os.path.splitext(INPUT_MP3_FILE)[0] + "_refined.txt"

sentence_count = refine_transcription(
    input_file=INPUT_MP3_FILE,
    output_file=OUTPUT_FILE,
    model=model,
    beam_size=5,          # í•„ìš” ì‹œ ì¡°ì •
    overlap_sec=2,        # í•„ìš” ì‹œ ì¡°ì •
    batch_sentence_count=20  # í•„ìš” ì‹œ ì¡°ì •
)

print(f"ì´ ë¬¸ì¥ ìˆ˜: {sentence_count}")
==========================================================
ğŸ’¡ í´ë” ë‚´ ëª¨ë“  MP3 ì²˜ë¦¬ ì˜ˆì‹œ
==========================================================

# process_mp3_files.py ì°¸ê³ 
# - INPUT_DIR í´ë” ë‚´ ëª¨ë“  MP3 íŒŒì¼ì„ ìˆ«ì ìˆœìœ¼ë¡œ ì²˜ë¦¬
# - ì¤‘ë³µ ì œê±° + ì§§ì€ ë¬¸ì¥ ì œê±° + ë§ì¶¤ë²• êµì •
# - output TXT íŒŒì¼ê³¼ metadata.json ìƒì„±

==========================================================
"""
import os
import json
import re
import torch
from refine_transcription import refine_transcription
from faster_whisper import WhisperModel
from tqdm import tqdm

# -------------------- ì„¤ì • --------------------
BASE_DIR = "./ë³´ì´ìŠ¤ í”¼ì‹± ë°ì´í„°(ê¸ˆê°ì›)"
INPUT_FOLDERS = ["ë°”ë¡œ ì´ ëª©ì†Œë¦¬", "ëŒ€ì¶œ ì‚¬ê¸°í˜•", "ìˆ˜ì‚¬ê¸°ê´€ ì‚¬ì¹­í˜•"]
OUTPUT_DIR = os.path.join(BASE_DIR, "text_data")
os.makedirs(OUTPUT_DIR, exist_ok=True)

MODEL_SIZE = "large-v3"
BEAM_SIZE = 5
OVERLAP_SEC = 3
BATCH_SENTENCE_COUNT = 40

# -------------------- Whisper ëª¨ë¸ ë¡œë“œ --------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"
print(f"Using device: {device}, compute_type={compute_type}")

print(f"Loading faster-whisper model '{MODEL_SIZE}'...")
model = WhisperModel(MODEL_SIZE, device=device, compute_type=compute_type)
print("Whisper model loaded.")

# -------------------- ë©”íƒ€ë°ì´í„° êµ¬ì¡° --------------------
metadata = {
    "folders": {},
    "total_sentence_count": 0
}

file_global_index = 1  # ì €ì¥ íŒŒì¼ ë²ˆí˜¸ 1ë¶€í„° ì‹œì‘

# -------------------- í´ë” ìˆœíšŒ --------------------
for folder_name in INPUT_FOLDERS:
    input_path = os.path.join(BASE_DIR, folder_name)
    print(f"\n===== Processing folder: {folder_name} =====")

    # í•´ë‹¹ í´ë” ë‚´ MP3/WAV íŒŒì¼ ìˆ˜ì§‘
    file_list = [f for f in os.listdir(input_path) if f.lower().endswith((".mp3", ".wav"))]

    # ìˆ«ì ì¶”ì¶œ í›„ ì •ë ¬
    file_dict = {}
    for f in file_list:
        m = re.findall(r'\d+', f)
        if m:
            num = int(m[0])
            if num in file_dict:
                # ì¤‘ë³µ ì‹œ ì ‘ë¯¸ì‚¬ ë¶™ì´ê¸°
                suffix = 1
                while f"{num}_{suffix}" in file_dict:
                    suffix += 1
                file_dict[f"{num}_{suffix}"] = f
            else:
                file_dict[num] = f

    # ìˆ«ì ìˆœ ì •ë ¬
    sorted_keys = sorted(file_dict.keys(), key=lambda x: int(str(x).split("_")[0]))

    folder_start_index = file_global_index
    folder_sentence_count = 0
    converted_count = 0

    for key in tqdm(sorted_keys, desc=f"Files in {folder_name}", ncols=100):
        filename = file_dict[key]
        in_file = os.path.join(input_path, filename)
        out_filename = f"{file_global_index}.txt"
        out_file = os.path.join(OUTPUT_DIR, out_filename)

        # -------------------- ì´ë¯¸ ë³€í™˜ëœ íŒŒì¼ ì¡´ì¬í•˜ë©´ ê±´ë„ˆë›°ê¸° + sentence_count ë³µì› --------------------
        if os.path.exists(out_file):
            print(f"[SKIP] File #{file_global_index} exists â†’ Restoring metadata from {out_filename}")
            try:
                with open(out_file, "r", encoding="utf-8") as f:
                    restored_sentence_count = sum(1 for _ in f)
            except:
                restored_sentence_count = 0
            folder_sentence_count += restored_sentence_count
            metadata["total_sentence_count"] += restored_sentence_count
            converted_count += 1
            file_global_index += 1
            continue

        # -------------------- ë³€í™˜ ì‹¤í–‰ --------------------
        print(f"Processing file #{file_global_index}: {filename}")
        sentence_count = refine_transcription(
            input_file=in_file,
            output_file=out_file,
            model=model,
            beam_size=BEAM_SIZE,
            overlap_sec=OVERLAP_SEC,
            batch_sentence_count=BATCH_SENTENCE_COUNT
        )

        folder_sentence_count += sentence_count
        metadata["total_sentence_count"] += sentence_count
        converted_count += 1
        file_global_index += 1

    folder_end_index = file_global_index - 1

    # -------------------- í´ë” ë©”íƒ€ë°ì´í„° ê¸°ë¡ --------------------
    metadata["folders"][folder_name] = {
        "start": folder_start_index,
        "end": folder_end_index,
        "count": converted_count,
        "sentence_count": folder_sentence_count
    }

# -------------------- ì „ì²´ ë©”íƒ€ë°ì´í„° ì €ì¥ --------------------
meta_path = os.path.join(OUTPUT_DIR, "metadata.json")
with open(meta_path, "w", encoding="utf-8") as f:
    json.dump(metadata, f, ensure_ascii=False, indent=2)

print("\n===== All processing done =====")
print(f"Metadata saved at: {meta_path}")
