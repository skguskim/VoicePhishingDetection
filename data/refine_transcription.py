import os
from pydub.utils import which
from kospellpy import spell_init
from tqdm import tqdm
import re

# -------------------- ì „ì—­ í•¨ìˆ˜ --------------------
def correct_text_batch(spell_checker, text_batch):
    """í•˜ë‚˜ì˜ ë°°ì¹˜(ë¬¸ì¥ í•©ì¹œ ë¬¸ìì—´)ì— ëŒ€í•œ ë§ì¶¤ë²• êµì •"""
    try:
        corrected = spell_checker(text_batch)
        sentences = [s.strip() for s in re.split(r'(?<=[.?!])\s+', corrected) if s.strip()]
        return sentences
    except:
        return [s.strip() for s in re.split(r'(?<=[.?!])\s+', text_batch)]

def remove_duplicates_and_short(sentences, min_len=3):
    """
    - ì¤‘ë³µ ë¬¸ì¥ ì œê±°
    - ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œê±°
    """
    unique_sentences = []
    seen = set()
    for sentence in sentences:
        cleaned = sentence.rstrip(".!?").strip()
        if len(cleaned) < min_len:
            continue
        if cleaned not in seen:
            seen.add(cleaned)
            unique_sentences.append(sentence)
    return unique_sentences

# -------------------- ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ --------------------
def refine_transcription(
    input_file,
    output_file,
    model,
    beam_size=5,
    overlap_sec=2,
    batch_sentence_count=20
):
    # --- ffmpeg í™•ì¸ ---
    if which("ffmpeg") is None:
        print("Warning: ffmpeg not found. Audio conversion may fail.")

    print(f"ğŸ§ Transcribing: {input_file}")
    segments, _ = model.transcribe(
        input_file,
        beam_size=beam_size,
        language="ko",
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=400)
    )

    # --- segment -> ë¬¸ì¥ ë³€í™˜ + ì˜¤ë²„ë© ì¤‘ë³µ ì œê±° ---
    all_sentences = []
    last_end_time = 0
    last_sentence = None  # ì´ì „ segment ë§ˆì§€ë§‰ ë¬¸ì¥
    for seg in tqdm(segments, desc="Processing segments", ncols=100):
        seg_start = max(seg.start - overlap_sec, last_end_time)
        seg_end = seg.end
        text = seg.text.strip()
        if text and len(text) > 3 and any(c.isalnum() for c in text):
            split_sentences = [s.strip() for s in re.split(r'(?<=[.?!])\s+', text) if s.strip()]
            for s in split_sentences:
                # ì´ì „ segment ë§ˆì§€ë§‰ ë¬¸ì¥ê³¼ ë™ì¼í•˜ë©´ skip
                if s != last_sentence:
                    all_sentences.append(s)
                last_sentence = s
        last_end_time = seg_end

    # --- ì¤‘ë³µ ì œê±° + ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œê±° ---
    all_sentences = remove_duplicates_and_short(all_sentences, min_len=3)

    # --- ë§ì¶¤ë²• êµì • í›„ ì¤‘ë³µ ì œê±° ---
    spell_checker = spell_init()
    refined_sentences = []
    prev_sentence = None
    for i in tqdm(range(0, len(all_sentences), batch_sentence_count), desc="Spellchecking batches", ncols=100):
        batch_text = " ".join(all_sentences[i:i+batch_sentence_count])
        batch_refined = correct_text_batch(spell_checker, batch_text)
        # batch ë‚´ì—ì„œ ë§ˆì§€ë§‰ ë¬¸ì¥ê³¼ ì´ì „ ë¬¸ì¥ ë¹„êµí•˜ë©° ì¤‘ë³µ ì œê±°
        for s in batch_refined:
            if s != prev_sentence:
                refined_sentences.append(s)
            prev_sentence = s

    # --- ìµœì¢… TXT íŒŒì¼ ì €ì¥ ---
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as f:
        for sentence in refined_sentences:
            f.write(sentence + "\n")

    print(f"âœ… Saved refined text to: {output_file}")
    return len(refined_sentences)
